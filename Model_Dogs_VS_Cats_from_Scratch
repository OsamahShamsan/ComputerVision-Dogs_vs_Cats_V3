{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#                        INSTALL & IMPORTS","metadata":{}},{"cell_type":"code","source":"!pip install protobuf==6.33.0\n\nimport pkgutil\nimport importlib\nimport subprocess\nimport sys\n\ndef safe_import(name):\n    try:\n        module = importlib.import_module(name)\n        return getattr(module, '__version__', 'unknown')\n    except Exception as e:\n        return f\"ERROR: {e}\"\n\nprint(\"PYTHON:\", sys.version)\n\npackages = [\n    \"numpy\",\n    \"tensorflow\",\n    \"scipy\",\n    \"sklearn\",\n    \"matplotlib\",\n    \"albumentations\",\n    \"albucore\",\n    \"cv2\",\n    \"protobuf\",\n    \"pydantic\",\n    \"pandas\",\n]\n\nprint(\"\\n=== INSTALLED PACKAGES ===\")\nfor p in packages:\n    print(f\"{p:15} {safe_import(p)}\")\n\nprint(\"\\n=== GPU INFO ===\")\ntry:\n    import tensorflow as tf\n    print(\"TensorFlow GPUs:\", tf.config.list_physical_devices(\"GPU\"))\nexcept Exception as e:\n    print(\"TensorFlow import error:\", e)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install albumentations==1.4.13 --no-deps\n!pip install albucore==0.0.34 --no-deps","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nprint(np.__version__)\n\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nprint(np.__version__)\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport albumentations as A\nprint(A.__version__)\n\nfrom albumentations.core.bbox_utils import denormalize_bboxes\n\n# reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nprint(\"TensorFlow:\", tf.__version__)\nprint(\"GPUs:\", tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MIXED PRECISION + MIRRORED STRATEGY","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('float32')\n\nstrategy = tf.distribute.MirroredStrategy()\nnum_gpus = strategy.num_replicas_in_sync\n\nBATCH_PER_GPU = 32\nGLOBAL_BATCH = BATCH_PER_GPU * num_gpus\nIMG_SIZE = 256","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#                     DATA EXTRACTION (KAGGLE DATASET)","metadata":{}},{"cell_type":"code","source":"dataset_base = \"/kaggle/input/dogs-vs-cats\"\nextract_dir = \"/kaggle/working/extracted\"\nos.makedirs(extract_dir, exist_ok=True)\n\nimport zipfile\n\nif not os.path.exists(f\"{extract_dir}/train\"):\n    with zipfile.ZipFile(f\"{dataset_base}/train.zip\", \"r\") as z:\n        z.extractall(extract_dir)\n\nif not os.path.exists(f\"{extract_dir}/test1\"):\n    with zipfile.ZipFile(f\"{dataset_base}/test1.zip\", \"r\") as z:\n        z.extractall(extract_dir)\n\ntrain_raw = f\"{extract_dir}/train\"\ntest_raw  = f\"{extract_dir}/test1\"\n\ntrain_files = sorted([f for f in os.listdir(train_raw) if f.endswith(\".jpg\")])\ncats = [f for f in train_files if f.startswith(\"cat\")]\ndogs = [f for f in train_files if f.startswith(\"dog\")]\n\nfrom sklearn.model_selection import train_test_split\ncat_train, cat_val = train_test_split(cats, test_size=0.2, random_state=42)\ndog_train, dog_val = train_test_split(dogs, test_size=0.2, random_state=42)\n\nbase = \"/kaggle/working/data\"\ntrain_dir = f\"{base}/train\"\nval_dir   = f\"{base}/val\"\n\nfor split in [train_dir, val_dir]:\n    for cls in [\"cat\", \"dog\"]:\n        os.makedirs(f\"{split}/{cls}\", exist_ok=True)\n\nimport shutil\ndef cp(files, src, dst):\n    for f in files:\n        shutil.copy(f\"{src}/{f}\", f\"{dst}/{f}\")\n\ncp(cat_train, train_raw, f\"{train_dir}/cat\")\ncp(cat_val,   train_raw, f\"{val_dir}/cat\")\ncp(dog_train, train_raw, f\"{train_dir}/dog\")\ncp(dog_val,   train_raw, f\"{val_dir}/dog\")\n\ntotal_train = len(cat_train) + len(dog_train)\ntotal_val   = len(cat_val)   + len(dog_val)\n\nprint(\"Train samples:\", total_train)\nprint(\"Val samples:\", total_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#                    ALBUMENTATIONS PIPELINE","metadata":{}},{"cell_type":"code","source":"\ntrain_aug = A.Compose([\n    A.RandomResizedCrop(size=(IMG_SIZE, IMG_SIZE), scale=(0.75, 1.0)),\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(20, p=0.5),\n    A.ColorJitter(0.3,0.3,0.3,0.05, p=0.8),\n    A.GaussianBlur(p=0.2),\n    A.RandomBrightnessContrast(p=0.5),\n], p=1.0)\n\nval_aug = A.Compose([\n    A.Resize(IMG_SIZE, IMG_SIZE)\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#               MIXUP + CUTMIX","metadata":{}},{"cell_type":"code","source":"def mixup_cutmix(images, labels, alpha=0.4):\n    batch_size = tf.shape(images)[0]\n    idx = tf.random.shuffle(tf.range(batch_size))\n    \n    lam = tf.constant(np.random.beta(alpha, alpha), dtype=tf.float32)\n    use_cutmix = tf.less(tf.random.uniform(()), 0.5)\n\n    def do_cutmix():\n        h, w = IMG_SIZE, IMG_SIZE\n\n        cut_rat = tf.sqrt(1.0 - lam)\n        cut_w = tf.cast(w * cut_rat, tf.int32)\n        cut_h = tf.cast(h * cut_rat, tf.int32)\n\n        cx = tf.random.uniform((), 0, w, dtype=tf.int32)\n        cy = tf.random.uniform((), 0, h, dtype=tf.int32)\n\n        x1 = tf.clip_by_value(cx - cut_w // 2, 0, w)\n        x2 = tf.clip_by_value(cx + cut_w // 2, 0, w)\n        y1 = tf.clip_by_value(cy - cut_h // 2, 0, h)\n        y2 = tf.clip_by_value(cy + cut_h // 2, 0, h)\n\n        images2 = tf.gather(images, idx)\n\n        pad_left = x1\n        pad_right = w - x2\n        pad_top = y1\n        pad_bottom = h - y2\n\n        cut_region = images2[:, y1:y2, x1:x2, :]\n        cutout = tf.pad(cut_region,\n                        [[0, 0],\n                         [pad_top, pad_bottom],\n                         [pad_left, pad_right],\n                         [0, 0]])\n\n        area = tf.cast((x2 - x1) * (y2 - y1), tf.float32)\n        lam_adj = 1 - area / tf.cast(h * w, tf.float32)\n\n        new_images = images * (1 - tf.clip_by_value(cutout, 0, 1)) + cutout\n        new_labels = lam_adj * labels + (1.0 - lam_adj) * tf.gather(labels, idx)\n\n        return new_images, new_labels\n\n    def do_mixup():\n        images2 = tf.gather(images, idx)\n        new_images = lam * images + (1 - lam) * images2\n        new_labels = lam * labels + (1 - lam) * tf.gather(labels, idx)\n        return new_images, new_labels\n\n    return tf.cond(use_cutmix, do_cutmix, do_mixup)\n\n\ndef apply_mix(images, labels):\n    new_images, new_labels = tf.py_function(\n        func=lambda x, y: mixup_cutmix(x, y),\n        inp=[images, labels],\n        Tout=[tf.float32, tf.float32]\n    )\n    new_images.set_shape([None, IMG_SIZE, IMG_SIZE, 3])\n    new_labels.set_shape([None, 2])\n    return new_images, new_labels\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DATASET BUILDERS","metadata":{}},{"cell_type":"code","source":"def load_aug(path, label, is_train=True):\n    img = tf.io.read_file(path)\n    img = tf.io.decode_jpeg(img, channels=3).numpy()\n    if is_train:\n        img = train_aug(image=img)[\"image\"]\n    else:\n        img = val_aug(image=img)[\"image\"]\n    img = img.astype(np.float32) / 255.0\n    return img, label\n\ndef tf_load(path, label, is_train=True):\n    img, lab = tf.py_function(\n        lambda p, l: load_aug(p, l, is_train),\n        [path, label],\n        [tf.float32, tf.float32]\n    )\n    img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n    lab.set_shape([2])\n    return img, lab\n\ndef make_ds(folder, batch=GLOBAL_BATCH, is_train=True):\n    paths = []\n    labels = []\n\n    for cls, i in [(\"cat\", 0), (\"dog\", 1)]:\n        fs = tf.io.gfile.glob(f\"{folder}/{cls}/*.jpg\")\n        paths.extend(fs)\n        labels.extend([i]*len(fs))\n\n    paths = tf.constant(paths)\n    labels = tf.one_hot(labels, 2)\n\n    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n\n    if is_train:\n        ds = ds.shuffle(20000)\n\n    ds = ds.map(lambda p, l: tf_load(p, l, is_train),\n                num_parallel_calls=tf.data.AUTOTUNE)\n\n    ds = ds.batch(batch)\n    ds = ds.prefetch(tf.data.AUTOTUNE)\n\n    return ds\n\ntrain_ds = make_ds(train_dir, is_train=True).map(apply_mix, num_parallel_calls=tf.data.AUTOTUNE)\nval_ds   = make_ds(val_dir,   is_train=False)\n\nfor x, y in train_ds.take(1):\n    print(x.shape, y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CONVNEXT-BASE ARCHITECTURE (FROM SCRATCH)","metadata":{}},{"cell_type":"code","source":"def convnext_block(x, dim):\n    shortcut = x\n    x = layers.DepthwiseConv2D(kernel_size=7, padding=\"same\")(x)\n    x = layers.LayerNormalization()(x)\n    x = layers.Dense(dim * 4, activation=\"gelu\")(x)\n    x = layers.Dense(dim)(x)\n    return layers.Add()([shortcut, x])\n\n\ndef build_convnext_base():\n    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n\n    dims  = [128, 256, 512, 1024]\n    depth = [3, 3, 27, 3]\n\n    x = layers.Conv2D(128, 4, strides=4)(inputs)\n    x = layers.LayerNormalization()(x)\n\n    for dim, d in zip(dims, depth):\n        for _ in range(d):\n            x = convnext_block(x, dim)\n        x = layers.Conv2D(dim * 2, 2, strides=2)(x)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.LayerNormalization()(x)\n    x = layers.Dense(256, activation=\"gelu\")(x)\n\n    outputs = layers.Dense(2, activation=\"softmax\", dtype=\"float32\")(x)\n    return keras.Model(inputs, outputs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LEARNING RATE SCHEDULE + OPTIMIZER","metadata":{}},{"cell_type":"code","source":"steps_per_epoch = total_train // GLOBAL_BATCH\n\nlr_schedule = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate=1e-3,\n    decay_steps=steps_per_epoch * 100,\n    alpha=1e-5,\n)\n\nwith strategy.scope():\n    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n    model = build_convnext_base()\n\n    model.compile(\n        optimizer=optimizer,\n        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n        metrics=[\"accuracy\"]\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EMA (EXPONENTIAL MOVING AVERAGE)","metadata":{}},{"cell_type":"code","source":"class EMA_Callback(keras.callbacks.Callback):\n    def __init__(self, ema_model, decay=0.999):\n        super().__init__()\n        self.ema_model = ema_model\n        self.decay = decay\n\n    def on_train_batch_end(self, batch, logs=None):\n        for w, ema_w in zip(model.weights, self.ema_model.weights):\n            ema_w.assign(self.decay * ema_w + (1 - self.decay) * w)\n\nema_model = build_convnext_base()\nfor w, ema_w in zip(model.weights, ema_model.weights):\n    ema_w.assign(w)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#                                TRAIN","metadata":{}},{"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        patience=25,\n        restore_best_weights=True\n    ),\n    keras.callbacks.ModelCheckpoint(\n        \"/kaggle/working/best_model.h5\",\n        monitor='val_accuracy',\n        save_best_only=True\n    ),\n    EMA_Callback(ema_model)\n]\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=100,\n    callbacks=callbacks\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LOAD BEST MODEL & USE EMA WEIGHTS","metadata":{}},{"cell_type":"code","source":"best_model = keras.models.load_model(\"/kaggle/working/best_model.h5\")\n\n# Swap EMA weights into a fresh model\nema_best = build_convnext_base()\nfor w, ema_w in zip(best_model.weights, ema_best.weights):\n    ema_w.assign(w)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VALIDATION EVALUATION + (OPTIONAL ACCURACY PRINT) + TEST SET INFERENCE + SUBMISSION CSV","metadata":{}},{"cell_type":"code","source":"preds = []\ntrue = []\n\nfor imgs, labels in val_ds:\n    p = ema_best.predict(imgs)\n    preds.extend(np.argmax(p, axis=1))\n    true.extend(np.argmax(labels.numpy(), axis=1))\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(classification_report(true, preds, target_names=[\"Cat\", \"Dog\"]))\n\ncm = confusion_matrix(true, preds)\nplt.imshow(cm, cmap=\"Blues\")\nplt.title(\"Confusion Matrix\")\nplt.colorbar()\nplt.show()\n\n\nval_accuracy = np.mean(np.array(preds) == np.array(true))\nprint(\"Validation Accuracy:\", val_accuracy)\n\ntest_files = sorted([f for f in os.listdir(test_raw) if f.endswith('.jpg')])\n\ntest_imgs = []\n\nfor f in test_files:\n    path = f\"{test_raw}/{f}\"\n    img = tf.io.read_file(path)\n    img = tf.io.decode_jpeg(img, channels=3).numpy()\n    img = val_aug(image=img)[\"image\"]\n    img = img.astype(np.float32) / 255.0\n    test_imgs.append(img)\n\ntest_imgs = np.array(test_imgs, dtype=np.float32)\nprobs = ema_best.predict(test_imgs)[:, 1]  # Dog probability\n\nids = [int(f.split('.')[0]) for f in test_files]\n\nimport pandas as pd\nsubmission = pd.DataFrame({'id': ids, 'label': probs})\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint(\"Submission saved â†’ /kaggle/working/submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}